# PLS-DNN: Seguran√ßa de Camada F√≠sica em Redes 6G com Deep Learning

![Status](https://img.shields.io/badge/Status-Conclu√≠do-green)
![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Framework](https://img.shields.io/badge/Framework-PyTorch-EE4C2C)
![MIT](https://img.shields.io/badge/License-MIT-blue)

Reposit√≥rio oficial do projeto da disciplina de **Seguran√ßa da Informa√ß√£o** (2025.2) da **Universidade Federal do Agreste de Pernambuco (UFAPE)**.

## Sobre o Projeto

Este projeto consiste em uma investiga√ß√£o sobre a aplica√ß√£o de Deep Learning para garantir a seguran√ßa na camada f√≠sica (Physical Layer Security - PLS) em redes m√≥veis de sexta gera√ß√£o (6G). Diferente da criptografia convencional, o sistema utiliza as caracter√≠sticas estoc√°sticas do canal de comunica√ß√£o para proteger os dados.

A simula√ß√£o foca em canais com desvanecimento Rayleigh, modelando cen√°rios de alta mobilidade onde o receptor leg√≠timo utiliza a informa√ß√£o de estado do canal ($CSI$) para decodificar a mensagem. O objetivo central √© demonstrar como uma Rede Neural Profunda ($DNN$), aliada a t√©cnicas de corre√ß√£o de erro ($FEC$), pode criar um canal de comunica√ß√£o confi√°vel e seguro contra interceptadores passivos, superando m√©todos lineares tradicionais em cen√°rios de distor√ß√£o de hardware.

A implementa√ß√£o atual compara tr√™s abordagens:

Zero-Forcing (ZF): Baseline linear tradicional (falha sob distor√ß√£o n√£o-linear).

Maximum Likelihood (ML): Limite te√≥rico √≥timo (alta complexidade computacional).

Deep Neural Network (DNN): Proposta baseada em dados (alta robustez e baixa complexidade).

## üìÇ Estrutura do Reposit√≥rio

O projeto foi reestruturado para suportar m√∫ltiplos cen√°rios de forma modular, separando experimentos lineares (BPSK) de n√£o-lineares (16-QAM com HPA).

```bash
.
‚îú‚îÄ‚îÄ docs/                       # Documenta√ß√£o acad√™mica e artefatos
‚îú‚îÄ‚îÄ files/                      # Arquivos auxiliares (LaTeX, Refer√™ncias)
‚îú‚îÄ‚îÄ results/                    # Gr√°ficos gerados automaticamente
‚îú‚îÄ‚îÄ src/                        # C√≥digo-fonte modular
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Orquestrador (Executa toda a pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ linear/                 # Cen√°rio 1: BPSK (Valida√ß√£o de Baseline)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear_main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stress_test.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ communication.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fec_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ non_linear/             # Cen√°rio 2: 16-QAM + HPA (Desafio 6G)
‚îÇ       ‚îú‚îÄ‚îÄ nl_main.py
‚îÇ       ‚îú‚îÄ‚îÄ stress_test.py
‚îÇ       ‚îú‚îÄ‚îÄ communication.py
‚îÇ       ‚îú‚îÄ‚îÄ models.py
‚îÇ       ‚îî‚îÄ‚îÄ fec_utils.py
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt# Pasta central de sa√≠da
```

## üöÄ Como Rodar Localmente

Siga os passos abaixo para clonar e executar a simula√ß√£o no seu ambiente Linux.

### 1. Pr√©-requisitos
Certifique-se de ter o **Python 3** e o **Git** instalados.

### 2. Clonar o Reposit√≥rio
```bash
git clone [https://github.com/fernando7492/projeto-devops-time-SI.git](https://github.com/fernando7492/projeto-devops-time-SI.git)
cd projeto-devops-time-SI/codes
```

### 3. Configurar o Ambiente Virtual
Recomendamos usar um ambiente virtual (`venv`) para isolar as depend√™ncias.

```bash
# Criar o ambiente virtual (na pasta oculta .venv)
python3 -m venv .venv

# Ativar o ambiente
source .venv/bin/activate
```

### 4. Instalar Depend√™ncias
Instale as bibliotecas necess√°rias (`torch`, `numpy`, `scipy`, `matplotlib`).

```bash
pip install -r requirements.txt
```

> **Nota:** Se voc√™ n√£o possui uma GPU dedicada ou tem pouco espa√ßo em disco, use o comando abaixo para instalar a vers√£o leve (CPU-only) do PyTorch:

```bash
pip install torch --index-url [https://download.pytorch.org/whl/cpu](https://download.pytorch.org/whl/cpu)
pip install numpy scipy matplotlib
```

### 5. Executar a simula√ß√£o completa
Execute o script:

```bash
python main.py
```

### üîç O que esperar da execu√ß√£o?
1.  O script detectar√° automaticamente seu hardware (CPU ou GPU).
2.  Executar√° os treinamentos para BPSK e 16-QAM.
3.  Realizar√° os testes de estresse comparando a IA com algoritmos cl√°ssicos (ZF e ML).
4.  Os resultados gr√°ficos ser√£o salvos automaticamente na pasta results/.

---

## Resultados

A simula√ß√£o gera gr√°ficos comparativos de Taxa de Erro de Bit (BER) versus Rela√ß√£o Sinal-Ru√≠do (SNR).

1. Cen√°rio Linear (Baseline BPSK)

Neste cen√°rio, a DNN atinge a otimalidade matem√°tica, empatando tecnicamente com o equalizador Zero-Forcing em condi√ß√µes ideais, mas mantendo o sigilo contra a interceptadora (Eve).

2. Cen√°rio N√£o-Linear (Desafio 16-QAM + HPA)

Aqui, a superioridade da IA se torna evidente. Devido √† distor√ß√£o do amplificador de pot√™ncia, o m√©todo linear cl√°ssico (ZF) colapsa, apresentando um alto piso de erro. A DNN, por sua vez, aprende a curva de distor√ß√£o e recupera o sinal com precis√£o.


![Gr√°fico do cen√°rio linear](results/linear_comparative_result.png)
![Gr√°fico de Converg√™ncia do cen√°rio n√£o-linear](results/non_linear_comparative_result.png)

## Teste de estresse
Em cen√°rios reais de redes 6G (V2X), a estimativa do estado do canal ($CSI$) raramente √© perfeita. Para validar a robustez, submetemos os receptores a um teste de estresse variando o erro de estima√ß√£o de 0% a 50%.

Conclus√£o Principal: A DNN demonstrou ser mais robusta que o Maximum Likelihood (ML) em cen√°rios de alta incerteza (erro de CSI > 10%), provando ser a solu√ß√£o ideal para ambientes din√¢micos onde a matem√°tica r√≠gida falha.

![Resili√™ncia da DNN a Erros de Estima√ß√£o de Canal](results/non_linear_stress_test_zf.png)

---

## üë• Equipe
* [**Emanuel Reino**](https://github.com/Emanuel-Al)
* [**Fernando Emidio**](https://github.com/Fernando7492)
* [**Gustavo Wanderley**](https://github.com/MESTREGUGABr)
* [**Pedro William**](https://github.com/pedrowillliam)
* [**Pedro Jos√©**](https://github.com/PJota021)
## Professor coordenador

* [**Professor Sergio Mendon√ßa**](https://github.com/sftom)

---
Desenvolvido no contexto acad√™mico da UFAPE.
